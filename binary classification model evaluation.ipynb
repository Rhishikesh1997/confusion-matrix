{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31b759ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assuming you have the true labels and predicted labels stored in variables y_true and y_pred respectively\n",
    "y_true = [0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1]\n",
    "y_pred = [0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1]\n",
    "\n",
    "# Define the class labels\n",
    "class_labels = ['Spam', 'Non-Spam']\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Transpose the confusion matrix\n",
    "cm_transposed = np.transpose(cm)\n",
    "\n",
    "# Create a heatmap of the transposed confusion matrix\n",
    "sns.heatmap(cm_transposed, annot=True, cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\n",
    "\n",
    "# Add labels, title, and axis ticks\n",
    "plt.xlabel('True Class Labels')\n",
    "plt.ylabel('Predicted Class Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "752aa67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision : 0.8333333333333334\n",
      "racall/TPR : 0.7142857142857143\n",
      "F1-score : 0.7692307692307692\n",
      "accuracy : 0.8125\n",
      "specificity : 0.8888888888888888\n",
      "FPR : 0.1111111111111111\n",
      "FNR : 0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "# precision , recall/TPR , f1 score , accuracy , TNR/specificity , FPR , FNR\n",
    "\n",
    "TP=5\n",
    "FP=1\n",
    "FN=2\n",
    "TN=8\n",
    "\n",
    "#precision\n",
    "precision= TP / (TP+FP)\n",
    "print(\"precision : {}\".format(precision))\n",
    "\n",
    "# reacll\n",
    "recall=TP/(TP+FN)\n",
    "print(\"racall/TPR : {}\".format(recall))\n",
    "\n",
    "#f1score\n",
    "f1_Score=(2*precision*recall)/(precision+recall)\n",
    "print(\"F1-score : {}\".format(f1_Score))\n",
    "\n",
    "#accuracy\n",
    "accuracy=(TP+TN)/(TP+TN+FP+FN)\n",
    "print(\"accuracy : {}\".format(accuracy))\n",
    "\n",
    "#TNR/specificity\n",
    "specificity=TN/(TN+FP)\n",
    "print(\"specificity : {}\".format(specificity))\n",
    "\n",
    "#FPR\n",
    "FPR=FP/(FP+TN)\n",
    "print(\"FPR : {}\".format(FPR))\n",
    "\n",
    "#FNR\n",
    "FNR=FN/(TP+FN)\n",
    "print(\"FNR : {}\".format(FNR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b428a723",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d53d5cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.71      0.77         7\n",
      "           1       0.80      0.89      0.84         9\n",
      "\n",
      "    accuracy                           0.81        16\n",
      "   macro avg       0.82      0.80      0.81        16\n",
      "weighted avg       0.81      0.81      0.81        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "666211b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision : 0.8\n",
      "racall/TPR : 0.8888888888888888\n",
      "F1-score : 0.8421052631578948\n",
      "accuracy : 0.8125\n",
      "specificity : 0.7142857142857143\n",
      "FPR : 0.2857142857142857\n",
      "FNR : 0.1111111111111111\n"
     ]
    }
   ],
   "source": [
    "# precision , recall/TPR , f1 score , accuracy , TNR/specificity , FPR , FNR\n",
    "# in case of non spam class\n",
    "TP=8\n",
    "FP=2\n",
    "FN=1\n",
    "TN=5\n",
    "\n",
    "#precision\n",
    "precision= TP / (TP+FP)\n",
    "print(\"precision : {}\".format(precision))\n",
    "\n",
    "# reacll\n",
    "recall=TP/(TP+FN)\n",
    "print(\"racall/TPR : {}\".format(recall))\n",
    "\n",
    "#f1score\n",
    "f1_Score=(2*precision*recall)/(precision+recall)\n",
    "print(\"F1-score : {}\".format(f1_Score))\n",
    "\n",
    "#accuracy\n",
    "accuracy=(TP+TN)/(TP+TN+FP+FN)\n",
    "print(\"accuracy : {}\".format(accuracy))\n",
    "\n",
    "#TNR/specificity\n",
    "specificity=TN/(TN+FP)\n",
    "print(\"specificity : {}\".format(specificity))\n",
    "\n",
    "#FPR\n",
    "FPR=FP/(FP+TN)\n",
    "print(\"FPR : {}\".format(FPR))\n",
    "\n",
    "#FNR\n",
    "FNR=FN/(TP+FN)\n",
    "print(\"FNR : {}\".format(FNR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a02866c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.71      0.77         7\n",
      "           1       0.80      0.89      0.84         9\n",
      "\n",
      "    accuracy                           0.81        16\n",
      "   macro avg       0.82      0.80      0.81        16\n",
      "weighted avg       0.81      0.81      0.81        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1782086",
   "metadata": {},
   "source": [
    "##  Example 1 : Precision is Important (e.g. Spam Email Detection)\n",
    "In the context of spam email detection, precision is crucial. High precision means that the classifier's predictions of spam emails are accurate, minimizing false positives. False positives occur when non-spam emails are classified as spam and end up in the spam folder. In this case, precision is more important because we want to avoid falsely flagging important emails as spam.\n",
    "\n",
    "Imagine a scenario where the system has high precision but moderate recall. It means that when the system flags an email as spam, it is highly likely to be an actual spam email. This is essential because false positives can be disruptive, causing users to miss important emails that end up in the spam folder. By maintaining high precision, you can minimize false positives and ensure that non-spam emails are not wrongly classified as spam.\n",
    "\n",
    "## Example 2 : Recall is Important (e.g. Disease Detection)\n",
    "Consider a scenario where the goal is to detect a rare but severe disease. In this case, recall becomes more critical. Recall measures the ability of the classifier to correctly identify positive instances (disease cases) out of the total actual positive instances. It is crucial to identify all positive cases, even if it means having some false positives. Missing a true positive (i.e., a diseased patient) can have severe consequences, so recall becomes the priority in this scenario.\n",
    "Consider a medical scenario where you are developing a diagnostic tool to detect a rare but life-threatening disease. The tool is designed to analyze various medical tests and provide a diagnosis of whether a patient has the disease or not. In this case, recall becomes the priority.\n",
    "\n",
    "If the diagnostic tool has high recall but lower precision, it means that it can effectively identify most of the patients who have the disease (true positives), even if it occasionally identifies some healthy individuals as having the disease (false positives). While false positives can lead to additional tests or unnecessary treatments for healthy individuals, missing a true positive (i.e., failing to diagnose a patient with the disease) can have severe consequences, potentially delaying treatment and impacting patient outcomes. Hence, in this scenario, maximizing recall is critical to ensure that no positive cases are missed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878f41b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed6192f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a105cba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c1e3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb580cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae208b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92efbcc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23656199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a760dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74959acf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b596751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a6c191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c08a6c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37786b86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361b4461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73042d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b106802a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84eb1349",
   "metadata": {},
   "source": [
    "##  Example 1 : Precision is Important (e.g., Spam Email Detection)\n",
    "In the context of spam email detection, precision is crucial. High precision means that the classifier's predictions of spam emails are accurate, minimizing false positives. False positives occur when non-spam emails are classified as spam and end up in the spam folder. In this case, precision is more important because we want to avoid falsely flagging important emails as spam.\n",
    "\n",
    "Imagine a scenario where the system has high precision but moderate recall. It means that when the system flags an email as spam, it is highly likely to be an actual spam email. This is essential because false positives can be disruptive, causing users to miss important emails that end up in the spam folder. By maintaining high precision, you can minimize false positives and ensure that non-spam emails are not wrongly classified as spam.\n",
    "\n",
    "## Example 2 : Recall is Important (e.g., Disease Detection)\n",
    "Consider a scenario where the goal is to detect a rare but severe disease. In this case, recall becomes more critical. Recall measures the ability of the classifier to correctly identify positive instances (disease cases) out of the total actual positive instances. It is crucial to identify all positive cases, even if it means having some false positives. Missing a true positive (i.e., a diseased patient) can have severe consequences, so recall becomes the priority in this scenario.\n",
    "Consider a medical scenario where you are developing a diagnostic tool to detect a rare but life-threatening disease. The tool is designed to analyze various medical tests and provide a diagnosis of whether a patient has the disease or not. In this case, recall becomes the priority.\n",
    "\n",
    "If the diagnostic tool has high recall but lower precision, it means that it can effectively identify most of the patients who have the disease (true positives), even if it occasionally identifies some healthy individuals as having the disease (false positives). While false positives can lead to additional tests or unnecessary treatments for healthy individuals, missing a true positive (i.e., failing to diagnose a patient with the disease) can have severe consequences, potentially delaying treatment and impacting patient outcomes. Hence, in this scenario, maximizing recall is critical to ensure that no positive cases are missed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49c7efea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision : 0.8333333333333334\n",
      "Recall/TPR : 0.7142857142857143\n",
      "Recall : 0.7692307692307692\n",
      "Accuracy : 0.8125\n",
      "TNR/ Specificity : 0.8888888888888888\n",
      "FNR : 0.2857142857142857\n",
      "FPR : 0.1111111111111111\n"
     ]
    }
   ],
   "source": [
    "##calculating evaluation metrics for spam class\n",
    "TP=5\n",
    "FP=1\n",
    "FN=2\n",
    "TN=8\n",
    "\n",
    "precision=TP/(TP+FP)\n",
    "print(\"precision : {}\".format(precision))\n",
    "\n",
    "recall=TP/(TP+FN)\n",
    "print(\"Recall/TPR : {}\".format(recall))\n",
    "\n",
    "f1_score = (2 * precision * recall) / (precision + recall)\n",
    "print(\"Recall : {}\".format(f1_score))\n",
    "\n",
    "accuracy=(TP+TN)/(TP+TN+FP+FN)\n",
    "print(\"Accuracy : {}\".format(accuracy))\n",
    "\n",
    "specificity=TN/(TN+FP)\n",
    "print(\"TNR/ Specificity : {}\".format(specificity))\n",
    "\n",
    "FNR=FN/(FN+TP)\n",
    "print(\"FNR : {}\".format(FNR))\n",
    "\n",
    "FPR=FP/(FP+TN)\n",
    "print(\"FPR : {}\".format(FPR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ef1a2c",
   "metadata": {},
   "source": [
    "# Note\n",
    "\n",
    "#### These precision, recalll and F1-Score metrics are bounded between 0 and 1 because they are proportions or ratios of different types of predictions made by the model, relative to the actual instances in the dataset. Values close to 1 indicate better performance, while values close to 0 indicate poorer performance in terms of precision, recall, or F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "463ca1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    non-spam       0.80      0.89      0.84         9\n",
      "        spam       0.83      0.71      0.77         7\n",
      "\n",
      "    accuracy                           0.81        16\n",
      "   macro avg       0.82      0.80      0.81        16\n",
      "weighted avg       0.81      0.81      0.81        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true_mapped,y_pred_mapped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebbb2f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision : 0.8\n",
      "Recall/TPR : 0.8888888888888888\n",
      "F1-Score : 0.8421052631578948\n",
      "Accuracy : 0.8125\n",
      "TNR/ Specificity : 0.7142857142857143\n",
      "FNR : 0.1111111111111111\n",
      "FPR : 0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "##calculating evaluation metrics for non-spam class\n",
    "TP=8\n",
    "FP=2\n",
    "FN=1\n",
    "TN=5\n",
    "\n",
    "precision=TP/(TP+FP)\n",
    "print(\"precision : {}\".format(precision))\n",
    "\n",
    "recall=TP/(TP+FN)\n",
    "print(\"Recall/TPR : {}\".format(recall))\n",
    "\n",
    "f1_score = (2 * precision * recall) / (precision + recall)\n",
    "print(\"F1-Score : {}\".format(f1_score))\n",
    "\n",
    "accuracy=(TP+TN)/(TP+TN+FP+FN)\n",
    "print(\"Accuracy : {}\".format(accuracy))\n",
    "\n",
    "specificity=TN/(TN+FP)\n",
    "print(\"TNR/ Specificity : {}\".format(specificity))\n",
    "\n",
    "FNR=FN/(FN+TP)\n",
    "print(\"FNR : {}\".format(FNR))\n",
    "\n",
    "FPR=FP/(FP+TN)\n",
    "print(\"FPR : {}\".format(FPR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901e8c9a",
   "metadata": {},
   "source": [
    "##  Example 1 : Precision is Important (e.g., Spam Email Detection)\n",
    "In the context of spam email detection, precision is crucial. High precision means that the classifier's predictions of spam emails are accurate, minimizing false positives. False positives occur when non-spam emails are classified as spam and end up in the spam folder. In this case, precision is more important because we want to avoid falsely flagging important emails as spam.\n",
    "\n",
    "Imagine a scenario where the system has high precision but moderate recall. It means that when the system flags an email as spam, it is highly likely to be an actual spam email. This is essential because false positives can be disruptive, causing users to miss important emails that end up in the spam folder. By maintaining high precision, you can minimize false positives and ensure that non-spam emails are not wrongly classified as spam.\n",
    "\n",
    "## Example 2 : Recall is Important (e.g., Disease Detection)\n",
    "Consider a scenario where the goal is to detect a rare but severe disease. In this case, recall becomes more critical. Recall measures the ability of the classifier to correctly identify positive instances (disease cases) out of the total actual positive instances. It is crucial to identify all positive cases, even if it means having some false positives. Missing a true positive (i.e., a diseased patient) can have severe consequences, so recall becomes the priority in this scenario.\n",
    "Consider a medical scenario where you are developing a diagnostic tool to detect a rare but life-threatening disease. The tool is designed to analyze various medical tests and provide a diagnosis of whether a patient has the disease or not. In this case, recall becomes the priority.\n",
    "\n",
    "If the diagnostic tool has high recall but lower precision, it means that it can effectively identify most of the patients who have the disease (true positives), even if it occasionally identifies some healthy individuals as having the disease (false positives). While false positives can lead to additional tests or unnecessary treatments for healthy individuals, missing a true positive (i.e., failing to diagnose a patient with the disease) can have severe consequences, potentially delaying treatment and impacting patient outcomes. Hence, in this scenario, maximizing recall is critical to ensure that no positive cases are missed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0231e3ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
